{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import ast \n","import json\n","import re\n","from pyspark.sql import SparkSession, functions, types\n","from google.cloud import storage"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["bucket_name = 'cmpt732-project-bucket'\n","bucket_path = 'gs://' + bucket_name"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<Blob: cmpt732-project-bucket, yelp_academic_ca_provinces.json, 1608694499755886>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_business.json, 1608694499981573>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_checkin.json, 1608694500209921>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_review.json, 1608694500560158>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_tip.json, 1608694500824867>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_user.json, 1608694501169468>\n"]}],"source":["gcs_client = storage.Client()\n","bucket = gcs_client.bucket(bucket_name)\n","\n","for obj in list(bucket.list_blobs(prefix='yelp_academic')):\n","    print(obj)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["#!hdfs dfs -ls 'gs://cmpt732-project-bucket/*.json' "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["#!scala -version"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName('YelpAnalysis')\\\n","    .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.15.1-beta') \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dataset_files = {\n","    'provinces': 'yelp_academic_ca_provinces.json',\n","    'businesses': 'yelp_academic_dataset_business.json',\n","    'checkins': 'yelp_academic_dataset_checkin.json',\n","    'reviews': 'yelp_academic_dataset_review.json',\n","    'users': 'yelp_academic_dataset_user.json'\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_business.csv file"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["df_provinces = spark.read.json(f'{bucket_path}/{dataset_files[\"provinces\"]}')\n","df_provinces.createOrReplaceTempView('VW_Province')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#spark.sql('SELECT CODE, PROVINCE FROM VW_Province').show(truncate=False)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["df_business = spark.read.json(f'{bucket_path}/{dataset_files[\"businesses\"]}')\n","df_business.createOrReplaceTempView(\"VW_Business\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#df_business.printSchema()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT STATE, COUNT(*) AS STATE_COUNT FROM VW_Business GROUP BY STATE ORDER BY 2 DESC''').show(10)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["df_business_CA = spark.sql('''\n","                            SELECT\n","                                BUSINESS_ID, NAME, STATE, CITY, \n","                                POSTAL_CODE, LATITUDE, LONGITUDE, \n","                                CATEGORIES, ATTRIBUTES\n","                            FROM\n","                                VW_Business VB \n","                                    INNER JOIN VW_Province VP ON VB.STATE = VP.CODE\n","                            WHERE\n","                                    IS_OPEN = '1'\n","                                AND POSTAL_CODE IS NOT NULL\n","                                AND LENGTH(POSTAL_CODE) = 7\n","                                AND LATITUDE IS NOT NULL\n","                                AND LONGITUDE IS NOT NULL\n","                                AND STARS IS NOT NULL\n","                                AND REVIEW_COUNT IS NOT NULL\n","                                AND CATEGORIES IS NOT NULL\n","                                AND ATTRIBUTES IS NOT NULL\n","                            ''').cache()\n","\n","df_business_CA.createOrReplaceTempView('VW_BUSINESS_CA')"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#spark.sql('SELECT * FROM VW_BUSINESS_CA').show(5)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT STATE, COUNT(*) AS STATE_COUNT FROM VW_BUSINESS_CA GROUP BY STATE ORDER BY 2 DESC''').show(10)"]},{"cell_type":"code","execution_count":19,"metadata":{"scrolled":false},"outputs":[],"source":["#spark.sql('''SELECT STATE, CITY, COUNT(*) AS CITY_COUNT FROM VW_BUSINESS_CA GROUP BY STATE, CITY ORDER BY 3 DESC''').show(10)"]},{"cell_type":"code","execution_count":20,"metadata":{"scrolled":false},"outputs":[],"source":["# prepare row wise category table\n","df_category_rw = spark.sql('''SELECT  \n","                                BUSINESS_ID AS B_ID,\n","                                UPPER(TRIM(CATEGORY)) as CATEGORY,\n","                                True AS SERVED\n","                              FROM \n","                              (\n","                                    SELECT  BUSINESS_ID, \n","                                            EXPLODE(SPLIT(CATEGORIES, ',')) as CATEGORY\n","                                    FROM    VW_BUSINESS_CA\n","                               ) ''')\n","\n","df_category_rw.createOrReplaceTempView('VW_CATEGORY_RW')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#spark.sql('SELECT * FROM VW_CATEGORY_RW').show(10)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["#spark.sql('SELECT CATEGORY, COUNT(B_ID) AS BUSINESS_COUNT FROM VW_CATEGORY_RW GROUP BY CATEGORY ORDER BY 2 DESC').show(10)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# prepare column wise category table\n","df_category_cw = df_category_rw.groupby('B_ID').pivot('CATEGORY').agg(functions.max('SERVED'))\n","df_category_cw = df_category_cw.select([functions.col(col).alias(\"CAT_\" + re.sub(\"[^0-9a-zA-Z$]+\",\"\",col)) for col in df_category_cw.columns])\n","df_category_cw.createOrReplaceTempView('VW_CATEGORY_CW')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#df_category_cw.show(10)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT RESTAURANTS, COUNT(B_ID) BUSINESS_COUNT FROM VW_CATEGORY_CW GROUP BY RESTAURANTS''').show(10)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["# Stg1 => First Stage: Including business categories as extra columns to business dataframe\n","df_business_CA_Stg1 = spark.sql('''SELECT \n","                                        BUSINESS_ID, NAME, STATE, CITY, \n","                                        POSTAL_CODE, LATITUDE, LONGITUDE, CATEGORIES, ATTRIBUTES,\n","                                        CAT.*\n","                                    FROM VW_BUSINESS_CA BSN\n","                                            INNER JOIN VW_CATEGORY_CW CAT ON BSN.BUSINESS_ID = CAT.CAT_BID ''')"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["df_business_CA_Stg1 = df_business_CA_Stg1.drop(\"CATEGORIES\", \"CAT_BID\")\n","df_business_CA_Stg1.createOrReplaceTempView('VW_BUSINESS_CA_Stg1')"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["#df_business_CA_Stg1.show(10)"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["def get_attribute_keys(struct_name):\n","    fields = json.loads(df_business_CA.schema.json())['fields']\n","\n","    attributes = []\n","\n","    for field in fields:\n","        if (field['name'] == struct_name):\n","\n","            sub_fields = field['type']['fields']\n","\n","            for sub_field in sub_fields:\n","                attributes += [sub_field['name']]\n","    \n","    return attributes\n","\n","attributes = get_attribute_keys('ATTRIBUTES')"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["#print(attributes)"]},{"cell_type":"code","execution_count":69,"metadata":{"scrolled":false},"outputs":[],"source":["@functions.udf(returnType=types.StringType())\n","def flatten_attributes(col_data):\n","    output = {}\n","\n","    for attribute in attributes:\n","        if (col_data[attribute] == None):\n","            output[attribute] = None\n","        elif str(col_data[attribute]).startswith('{'):\n","            col_sub_data = str(col_data[attribute]).split(',')\n","            \n","            for sub_data in col_sub_data:\n","                if (len(sub_data.split(':')) == 2):\n","                    sub_attr_key = sub_data.split(':')[0].replace('{', '').replace('\\'', '').strip()\n","                    sub_attr_val = sub_data.split(':')[1].replace('}', '').replace('\\'', '').strip()\n","                    output[attribute + \"_\" + sub_attr_key] = sub_attr_val\n","        else:\n","            output[attribute] = col_data[attribute]\n","\n","    return str(output) \\\n","                .replace('{', '') \\\n","                .replace('}','') \\\n","                .replace('\\'', '')\n","\n","spark.udf.register(\"FLATTEN\", flatten_attributes);"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# row wise attribute dataframe\n","df_attribute_rw = spark.sql('''\n","                            SELECT BUSINESS_ID AS B_ID,\n","                                   REPLACE(SPLIT(TRIM(ATTRIBUTE), ':')[0], \"'\", \"\") AS ATTR_KEY,\n","                                   UPPER(TRIM(SPLIT(ATTRIBUTE, ':')[1])) AS ATTR_VAL\n","                            FROM\n","                            (\n","                                SELECT BUSINESS_ID,\n","                                       EXPLODE(SPLIT(FLATTEN(ATTRIBUTES), ',')) AS ATTRIBUTE\n","                                FROM   VW_BUSINESS_CA )''')\n","\n","df_attribute_rw.createOrReplaceTempView('VW_ATTRIBUTE_RW')"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["#spark.sql(\"SELECT * FROM VW_ATTRIBUTE_RW\").show(5, False)"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# column wise attribute dataframe\n","df_attribute_cw = df_attribute_rw.groupby('B_ID').pivot('ATTR_KEY').agg(functions.max('ATTR_VAL'))\n","df_attribute_cw = df_attribute_cw.select([functions.col(col).alias(\"ATTR_\" + re.sub(\"[^0-9a-zA-Z$]+\",\"\",col)) for col in df_attribute_cw.columns])\n","df_attribute_cw.createOrReplaceTempView('VW_ATTRIBUTE_CW')"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["#df_attribute_cw.show(5)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["# Stg2 => Second Stage: Including attribute values as extra columns into business dataframe\n","df_business_CA_Stg2 = spark.sql('''SELECT BSN.*, ATR.* \n","                                   FROM \n","                                       VW_BUSINESS_CA_Stg1 BSN \n","                                           INNER JOIN VW_ATTRIBUTE_CW ATR ON BSN.BUSINESS_ID = ATR.ATTR_BID''')"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["df_business_CA_final = df_business_CA_Stg2.drop('ATTRIBUTES', 'ATTR_BID')"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["df_business_CA_final.createOrReplaceTempView('VW_BUSINESS_CA_FINAL')\n","df_business_CA_final.cache();"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["#df_business_CA_final.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_checkin.csv file"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["df_checkin = spark.read.json(f'{bucket_path}/{dataset_files[\"checkins\"]}')\n","df_checkin.createOrReplaceTempView(\"VW_Checkin\")"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["#df_checkin.printSchema()"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["#df_checkin.show(5)"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["df_checkin_valid = spark.sql('''SELECT CHK.*\n","                                FROM VW_CHECKIN CHK\n","                                      INNER JOIN VW_BUSINESS_CA_FINAL BSN\n","                                          ON BSN.BUSINESS_ID = CHK.BUSINESS_ID ''')\n","\n","df_checkin_valid.createOrReplaceTempView('VW_CHECKIN_VALID')"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["df_checkin_exp = spark.sql('''\n","                            SELECT  BUSINESS_ID,\n","                                    FROM_UNIXTIME(UNIX_TIMESTAMP(TRIM(DATE), \"yyyy-MM-dd HH:mm:ss\")) AS DATE\n","                            FROM (\n","                                SELECT BUSINESS_ID, EXPLODE(SPLIT(DATE, \",\")) AS DATE\n","                                FROM   VW_CHECKIN_VALID )\n","                            WHERE  \n","                                    DATE IS NOT NULL\n","                                AND DATE != \"\" ''')"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["#df_checkin_exp.show(10)"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_review.csv file"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["df_review = spark.read.json(f'{bucket_path}/{dataset_files[\"reviews\"]}')\n","df_review.createOrReplaceTempView(\"VW_Review\")"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["#df_review.printSchema()"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["df_review_valid = spark.sql('''SELECT \n","                                    RVW.BUSINESS_ID,\n","                                    USER_ID,\n","                                    REGEXP_REPLACE(TEXT, '\\n', ' ') AS TEXT, \n","                                    TO_DATE(DATE) AS DATE,\n","                                    STARS,\n","                                    COOL,\n","                                    FUNNY,\n","                                    USEFUL\n","                                  FROM VW_REVIEW RVW\n","                                      INNER JOIN VW_BUSINESS_CA_FINAL BSN ON BSN.BUSINESS_ID = RVW.BUSINESS_ID\n","                                  WHERE\n","                                          TEXT IS NOT NULL\n","                                      AND USEFUL IS NOT NULL\n","                                      AND COOL IS NOT NULL\n","                                      AND FUNNY IS NOT NULL\n","                                      AND STARS IS NOT NULL AND STARS >= 0 AND STARS <= 5\n","                              ''')\n","\n","df_review_valid.createOrReplaceTempView('VW_REVIEW_VALID')"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["#df_review_valid.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_user.csv file"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["df_user = spark.read.json(f'{bucket_path}/{dataset_files[\"users\"]}')\n","df_user.createOrReplaceTempView(\"VW_User\")"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["#df_user.printSchema()"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["df_user_valid = spark.sql('''\n","                            SELECT\n","                                USR.USER_ID,\n","                                NAME,\n","                                COMPLIMENT_WRITER,\n","                                COMPLIMENT_PROFILE,\n","                                COMPLIMENT_PLAIN,\n","                                COMPLIMENT_PHOTOS,\n","                                COMPLIMENT_NOTE,\n","                                COMPLIMENT_MORE,\n","                                COMPLIMENT_LIST,\n","                                COMPLIMENT_HOT,\n","                                COMPLIMENT_FUNNY,\n","                                COMPLIMENT_CUTE,\n","                                COMPLIMENT_COOL,\n","                                USR.USEFUL,\n","                                USR.FUNNY,\n","                                FRIENDS,\n","                                FANS,\n","                                ELITE,\n","                                USR.COOL,\n","                                REVIEW_COUNT,\n","                                AVERAGE_STARS,\n","                                YELPING_SINCE\n","                            FROM VW_USER USR\n","                                INNER JOIN VW_REVIEW_VALID RVW ON RVW.USER_ID = USR.USER_ID\n","                        ''').cache()\n","\n","df_user_valid.createOrReplaceTempView('VW_USER_VALID')"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["#df_user_valid.show(5)"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["df_user_friends = spark.sql('''\n","                            SELECT DISTINCT\n","                                USER_ID,\n","                                TRIM(FRIEND_USER_ID) AS FRIEND_USER_ID\n","                            FROM (SELECT \n","                                    USER_ID,\n","                                    EXPLODE(SPLIT(FRIENDS, ',')) AS FRIEND_USER_ID\n","                                FROM \n","                                    VW_USER_VALID)\n","                            WHERE\n","                                    FRIEND_USER_ID IS NOT NULL\n","                                AND FRIEND_USER_ID <> 'None'\n","                ''')"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["#df_user_friends.show(10)"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["df_user_elites = spark.sql('''\n","                            SELECT DISTINCT\n","                                USER_ID,\n","                                TRIM(ELITE) AS ELITE\n","                            FROM (SELECT \n","                                    USER_ID,\n","                                    EXPLODE(SPLIT(ELITE, ',')) AS ELITE\n","                                FROM \n","                                    VW_USER_VALID)\n","                            WHERE\n","                                    ELITE IS NOT NULL\n","                                AND ELITE <> 'None'\n","                                AND ELITE <> ''\n","                ''')"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["#df_user_elites.show(10)"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["df_user_valid_final = df_user_valid.drop('ELITE', 'FRIENDS')"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["#df_user_valid_final.show(10)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["def write_to_bq(df, temp_bucket_name, ds_name, tbl_name):\n","    df.write \\\n","        .format('bigquery') \\\n","        .option('table', f'{ds_name}.{tbl_name}') \\\n","        .option(\"temporaryGcsBucket\", temp_bucket_name) \\\n","        .mode('overwrite') \\\n","        .save()"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["write_to_bq(df_provinces, bucket_name, 'yelp_dataset', 'provinces')"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["write_to_bq(df_business_CA_final, bucket_name, 'yelp_dataset', 'businesses')"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["write_to_bq(df_category_rw, bucket_name, 'yelp_dataset', 'categories')"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["write_to_bq(df_attribute_rw, bucket_name, 'yelp_dataset', 'attributes')"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["write_to_bq(df_checkin_exp, bucket_name, 'yelp_dataset', 'checkins')"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[],"source":["write_to_bq(df_review_valid, bucket_name, 'yelp_dataset', 'reviews')"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["write_to_bq(df_user_valid_final, bucket_name, 'yelp_dataset', 'users')"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[],"source":["write_to_bq(df_user_friends, bucket_name, 'yelp_dataset', 'user_friends')"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[],"source":["write_to_bq(df_user_elites, bucket_name, 'yelp_dataset', 'user_elites')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}