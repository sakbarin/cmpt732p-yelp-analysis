{"cells":[{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["import ast \n","import json\n","from pyspark.sql import SparkSession, functions, types\n","from google.cloud import storage"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["bucket_name = 'cmpt732-project-bucket'\n","bucket_path = 'gs://' + bucket_name"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<Blob: cmpt732-project-bucket, yelp_academic_ca_provinces.json, 1608694499755886>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_business.json, 1608694499981573>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_checkin.json, 1608694500209921>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_review.json, 1608694500560158>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_tip.json, 1608694500824867>\n","<Blob: cmpt732-project-bucket, yelp_academic_dataset_user.json, 1608694501169468>\n"]}],"source":["gcs_client = storage.Client()\n","bucket = gcs_client.bucket(bucket_name)\n","\n","for obj in list(bucket.list_blobs(prefix='yelp_academic')):\n","    print(obj)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-rwx------   3 root root        535 2020-12-23 03:34 gs://cmpt732-project-bucket/yelp_academic_ca_provinces.json\r\n","-rwx------   3 root root  152898689 2020-12-23 03:34 gs://cmpt732-project-bucket/yelp_academic_dataset_business.json\r\n","-rwx------   3 root root  449663480 2020-12-23 03:35 gs://cmpt732-project-bucket/yelp_academic_dataset_checkin.json\r\n","-rwx------   3 root root 6325565224 2020-12-23 03:35 gs://cmpt732-project-bucket/yelp_academic_dataset_review.json\r\n","-rwx------   3 root root  263489322 2020-12-23 03:35 gs://cmpt732-project-bucket/yelp_academic_dataset_tip.json\r\n","-rwx------   3 root root 3268069927 2020-12-23 03:35 gs://cmpt732-project-bucket/yelp_academic_dataset_user.json\r\n"]}],"source":["!hdfs dfs -ls 'gs://cmpt732-project-bucket/*.json' "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Scala code runner version 2.12.10 -- Copyright 2002-2019, LAMP/EPFL and Lightbend, Inc.\r\n"]}],"source":["!scala -version"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName('YelpAnalysis')\\\n","    .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.15.1-beta') \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["dataset_files = {\n","    'provinces': 'yelp_academic_ca_provinces.json',\n","    'businesses': 'yelp_academic_dataset_business.json',\n","    'checkins': 'yelp_academic_dataset_checkin.json',\n","    'reviews': 'yelp_academic_dataset_review.json',\n","    'users': 'yelp_academic_dataset_user.json'\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_business.csv file"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["df_provinces = spark.read.json(f'{bucket_path}/{dataset_files[\"provinces\"]}')\n","df_provinces.createOrReplaceTempView('VW_Province')"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["#spark.sql('SELECT * FROM VW_Province').show(truncate=False)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["df_business = spark.read.json(f'{bucket_path}/{dataset_files[\"businesses\"]}')\n","df_business.createOrReplaceTempView(\"VW_Business\")"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["#df_business.printSchema()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT STATE, COUNT(*) AS STATE_COUNT FROM VW_Business GROUP BY STATE ORDER BY 2 DESC''').show(10)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["df_business_CA = spark.sql('''\n","                            SELECT\n","                                BUSINESS_ID, NAME, STATE, CITY, POSTAL_CODE, LATITUDE, LONGITUDE, CATEGORIES, ATTRIBUTES\n","                            FROM\n","                                VW_Business VB \n","                                    INNER JOIN VW_Province VP ON VB.STATE = VP.CODE\n","                            WHERE\n","                                    IS_OPEN = '1'\n","                                AND POSTAL_CODE IS NOT NULL\n","                                AND LENGTH(POSTAL_CODE) = 7\n","                                AND LATITUDE IS NOT NULL\n","                                AND LONGITUDE IS NOT NULL\n","                                AND STARS IS NOT NULL\n","                                AND REVIEW_COUNT IS NOT NULL\n","                                AND CATEGORIES IS NOT NULL\n","                                AND ATTRIBUTES IS NOT NULL\n","                            ''').cache()\n","\n","df_business_CA.createOrReplaceTempView('VW_BUSINESS_CA')"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["#spark.sql('SELECT * FROM VW_BUSINESS_CA').show(5)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT STATE, COUNT(*) AS STATE_COUNT FROM VW_BUSINESS_CA GROUP BY STATE ORDER BY 2 DESC''').show(10)"]},{"cell_type":"code","execution_count":36,"metadata":{"scrolled":false},"outputs":[],"source":["#spark.sql('''SELECT STATE, CITY, COUNT(*) AS CITY_COUNT FROM VW_BUSINESS_CA GROUP BY STATE, CITY ORDER BY 3 DESC''').show(10)"]},{"cell_type":"code","execution_count":49,"metadata":{"scrolled":false},"outputs":[],"source":["df_business_CA_cat = spark.sql('''\n","                                SELECT \n","                                    BUSINESS_ID,\n","                                    TRIM(CATEGORY) as CATEGORY\n","                                FROM\n","                                    (\n","                                    SELECT \n","                                        BUSINESS_ID, \n","                                        EXPLODE(SPLIT(CATEGORIES, ',')) as CATEGORY\n","                                    FROM\n","                                        VW_BUSINESS_CA)\n","                                ''')\n","\n","df_business_CA_cat.createOrReplaceTempView('VW_BUSINESS_CA_CAT')"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT * FROM VW_BUSINESS_CA_CAT''').show(10, False)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT CATEGORY, COUNT(*) AS CATEGORY_COUNT FROM VW_BUSINESS_CA_CAT GROUP BY CATEGORY ORDER BY 2 DESC''').show(10)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["def get_attribute_keys(struct_name):\n","    fields = json.loads(df_business_CA.schema.json())['fields']\n","\n","    attributes = []\n","\n","    for field in fields:\n","        if (field['name'] == struct_name):\n","\n","            sub_fields = field['type']['fields']\n","\n","            for sub_field in sub_fields:\n","                attributes += [sub_field['name']]\n","    \n","    return attributes\n","\n","attributes = get_attribute_keys('ATTRIBUTES')"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["#print(attributes)"]},{"cell_type":"code","execution_count":59,"metadata":{"scrolled":false},"outputs":[],"source":["@functions.udf(returnType=types.StringType())\n","def flatten_attributes(col_data):\n","    output = {}\n","\n","    for attribute in attributes:\n","        if (col_data[attribute] == None):\n","            output[attribute] = None\n","        elif str(col_data[attribute]).startswith('{'):\n","            col_sub_data = str(col_data[attribute]).split(',')\n","            \n","            for sub_data in col_sub_data:\n","                if (len(sub_data.split(':')) == 2):\n","                    sub_attr_key = sub_data.split(':')[0].replace('{', '').replace('\\'', '').strip()\n","                    sub_attr_val = sub_data.split(':')[1].replace('}', '').replace('\\'', '').strip()\n","                    output[attribute + \"_\" + sub_attr_key] = sub_attr_val\n","        else:\n","            output[attribute] = col_data[attribute]\n","\n","    return str(output) \\\n","                .replace('{', '') \\\n","                .replace('}','') \\\n","                .replace('\\'', '')\n","\n","spark.udf.register(\"FLATTEN\", flatten_attributes);"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["df_business_CA_attr = spark.sql('''\n","                                SELECT\n","                                    BUSINESS_ID,\n","                                    REPLACE(SPLIT(TRIM(ATTRIBUTE), ':')[0], \"'\", \"\") AS ATTR_KEY,\n","                                    TRIM(SPLIT(ATTRIBUTE, ':')[1]) AS ATTR_VAL\n","                                FROM\n","                                (\n","                                    SELECT\n","                                        BUSINESS_ID,\n","                                        EXPLODE(SPLIT(FLATTEN(ATTRIBUTES), ',')) AS ATTRIBUTE\n","                                    FROM \n","                                        VW_BUSINESS_CA\n","                                )''')\n","\n","df_business_CA_attr.createOrReplaceTempView('VW_BUSINESS_CA_ATTR')"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["#spark.sql(\"SELECT * FROM VW_BUSINESS_CA_ATTR\").show(10, False)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["#spark.sql('''SELECT ATTR_VAL, COUNT(*) AS BUSINESS_COUNT FROM VW_BUSINESS_CA_ATTR WHERE ATTR_KEY = \"HasTV\" GROUP BY ATTR_VAL ''').show()"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["df_business_CA_final = df_business_CA.drop('CATEGORIES', 'ATTRIBUTES')\n","df_business_CA_final.createOrReplaceTempView('VW_BUSINESS_CA_FINAL')"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["#df_business_CA_final.show(10)"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_checkin.csv file"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["df_checkin = spark.read.json(f'{bucket_path}/{dataset_files[\"checkins\"]}')\n","df_checkin.createOrReplaceTempView(\"VW_Checkin\")"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["#df_checkin.printSchema()"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["#df_checkin.show(5)"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["df_checkin_valid = spark.sql('''SELECT \n","                                    VW_CHECKIN.*\n","                                  FROM VW_CHECKIN \n","                                      INNER JOIN VW_BUSINESS_CA_FINAL ON VW_BUSINESS_CA_FINAL.BUSINESS_ID = VW_CHECKIN.BUSINESS_ID\n","                              ''')\n","\n","df_checkin_valid.createOrReplaceTempView('VW_CHECKIN_VALID')"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["df_checkin_exp = spark.sql('''\n","                            SELECT \n","                                BUSINESS_ID,\n","                                FROM_UNIXTIME(UNIX_TIMESTAMP(TRIM(DATE), 'yyyy-MM-dd HH:mm:ss')) AS DATE\n","                            FROM (\n","                                SELECT\n","                                    BUSINESS_ID,\n","                                    EXPLODE(SPLIT(DATE, ',')) AS DATE\n","                                FROM \n","                                    VW_CHECKIN_VALID)\n","                            WHERE\n","                                DATE IS NOT NULL\n","                                AND DATE != ''\n","                            ''')"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["#df_checkin_exp.show(10)"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_review.csv file"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["df_review = spark.read.json(f'{bucket_path}/{dataset_files[\"reviews\"]}')\n","df_review.createOrReplaceTempView(\"VW_Review\")"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["#df_review.printSchema()"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["df_review_valid = spark.sql('''SELECT \n","                                    VW_REVIEW.BUSINESS_ID,\n","                                    USER_ID,\n","                                    REGEXP_REPLACE(TEXT, '\\n', ' ') AS TEXT, \n","                                    TO_DATE(DATE) AS DATE,\n","                                    STARS,\n","                                    COOL,\n","                                    FUNNY,\n","                                    USEFUL\n","                                  FROM VW_REVIEW \n","                                      INNER JOIN VW_BUSINESS_CA_FINAL ON VW_BUSINESS_CA_FINAL.BUSINESS_ID = VW_REVIEW.BUSINESS_ID\n","                                  WHERE\n","                                          TEXT IS NOT NULL\n","                                      AND USEFUL IS NOT NULL\n","                                      AND COOL IS NOT NULL\n","                                      AND FUNNY IS NOT NULL\n","                                      AND STARS IS NOT NULL AND STARS >= 0 AND STARS <= 5\n","                              ''')\n","\n","df_review_valid.createOrReplaceTempView('VW_REVIEW_VALID')"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["#df_review_valid.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["## Process yelp_academic_dataset_user.csv file"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["df_user = spark.read.json(f'{bucket_path}/{dataset_files[\"users\"]}')\n","df_user.createOrReplaceTempView(\"VW_User\")"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["#df_user.printSchema()"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["#df_user.show(5)"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["df_user_valid = spark.sql('''\n","                            SELECT\n","                                VW_USER.USER_ID,\n","                                NAME,\n","                                COMPLIMENT_WRITER,\n","                                COMPLIMENT_PROFILE,\n","                                COMPLIMENT_PLAIN,\n","                                COMPLIMENT_PHOTOS,\n","                                COMPLIMENT_NOTE,\n","                                COMPLIMENT_MORE,\n","                                COMPLIMENT_LIST,\n","                                COMPLIMENT_HOT,\n","                                COMPLIMENT_FUNNY,\n","                                COMPLIMENT_CUTE,\n","                                COMPLIMENT_COOL,\n","                                VW_USER.USEFUL,\n","                                VW_USER.FUNNY,\n","                                FRIENDS,\n","                                FANS,\n","                                ELITE,\n","                                VW_USER.COOL,\n","                                REVIEW_COUNT,\n","                                AVERAGE_STARS,\n","                                YELPING_SINCE\n","                            FROM VW_USER \n","                                INNER JOIN VW_REVIEW_VALID ON VW_REVIEW_VALID.USER_ID = VW_USER.USER_ID\n","                        ''').cache()\n","\n","df_user_valid.createOrReplaceTempView('VW_USER_VALID')"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["#df_user_valid.show(5)"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["df_user_friends = spark.sql('''\n","                            SELECT DISTINCT\n","                                USER_ID,\n","                                TRIM(FRIEND_USER_ID) AS FRIEND_USER_ID\n","                            FROM (SELECT \n","                                    USER_ID,\n","                                    EXPLODE(SPLIT(FRIENDS, ',')) AS FRIEND_USER_ID\n","                                FROM \n","                                    VW_USER_VALID)\n","                            WHERE\n","                                    FRIEND_USER_ID IS NOT NULL\n","                                AND FRIEND_USER_ID <> 'None'\n","                ''')"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["#df_user_friends.show(10)"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":["df_user_elites = spark.sql('''\n","                            SELECT DISTINCT\n","                                USER_ID,\n","                                TRIM(ELITE) AS ELITE\n","                            FROM (SELECT \n","                                    USER_ID,\n","                                    EXPLODE(SPLIT(ELITE, ',')) AS ELITE\n","                                FROM \n","                                    VW_USER_VALID)\n","                            WHERE\n","                                    ELITE IS NOT NULL\n","                                AND ELITE <> 'None'\n","                                AND ELITE <> ''\n","                ''')"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[],"source":["#df_user_elites.show(10)"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["df_user_valid_final = df_user_valid.drop('ELITE', 'FRIENDS')"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["#df_user_valid_final.show(10)"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[],"source":["def write_to_bq(df, temp_bucket_name, ds_name, tbl_name):\n","    df.write \\\n","        .format('bigquery') \\\n","        .option('table', f'{ds_name}.{tbl_name}') \\\n","        .option(\"temporaryGcsBucket\", temp_bucket_name) \\\n","        .mode('overwrite') \\\n","        .save()"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[],"source":["write_to_bq(df_provinces, bucket_name, 'yelp_dataset', 'provinces')"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["write_to_bq(df_business_CA_final, bucket_name, 'yelp_dataset', 'businesses')\n","write_to_bq(df_business_CA_cat, bucket_name, 'yelp_dataset', 'categories')\n","write_to_bq(df_business_CA_attr, bucket_name, 'yelp_dataset', 'attributes')"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["write_to_bq(df_checkin_exp, bucket_name, 'yelp_dataset', 'checkins')"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["write_to_bq(df_review_valid, bucket_name, 'yelp_dataset', 'reviews')"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["write_to_bq(df_user_valid_final, bucket_name, 'yelp_dataset', 'users')\n","write_to_bq(df_user_friends, bucket_name, 'yelp_dataset', 'user_friends')\n","write_to_bq(df_user_elites, bucket_name, 'yelp_dataset', 'user_elites')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}